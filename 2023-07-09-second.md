```python
!pip install kaggle
from google.colab import files
files.upload()
```

    Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
    Requirement already satisfied: kaggle in /usr/local/lib/python3.8/dist-packages (1.5.12)
    Requirement already satisfied: python-dateutil in /usr/local/lib/python3.8/dist-packages (from kaggle) (2.8.2)
    Requirement already satisfied: python-slugify in /usr/local/lib/python3.8/dist-packages (from kaggle) (8.0.0)
    Requirement already satisfied: urllib3 in /usr/local/lib/python3.8/dist-packages (from kaggle) (1.24.3)
    Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from kaggle) (2.25.1)
    Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.8/dist-packages (from kaggle) (1.15.0)
    Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from kaggle) (4.64.1)
    Requirement already satisfied: certifi in /usr/local/lib/python3.8/dist-packages (from kaggle) (2022.12.7)
    Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.8/dist-packages (from python-slugify->kaggle) (1.3)
    Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->kaggle) (2.10)
    Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->kaggle) (4.0.0)




     <input type="file" id="files-4bd5365b-ede4-493f-bab8-2a97d8e27b90" name="files[]" multiple disabled
        style="border:none" />
     <output id="result-4bd5365b-ede4-493f-bab8-2a97d8e27b90">
      Upload widget is only available when the cell has been executed in the
      current browser session. Please rerun this cell to enable.
      </output>
      <script>// Copyright 2017 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

/**
 * @fileoverview Helpers for google.colab Python module.
 */
(function(scope) {
function span(text, styleAttributes = {}) {
  const element = document.createElement('span');
  element.textContent = text;
  for (const key of Object.keys(styleAttributes)) {
    element.style[key] = styleAttributes[key];
  }
  return element;
}

// Max number of bytes which will be uploaded at a time.
const MAX_PAYLOAD_SIZE = 100 * 1024;

function _uploadFiles(inputId, outputId) {
  const steps = uploadFilesStep(inputId, outputId);
  const outputElement = document.getElementById(outputId);
  // Cache steps on the outputElement to make it available for the next call
  // to uploadFilesContinue from Python.
  outputElement.steps = steps;

  return _uploadFilesContinue(outputId);
}

// This is roughly an async generator (not supported in the browser yet),
// where there are multiple asynchronous steps and the Python side is going
// to poll for completion of each step.
// This uses a Promise to block the python side on completion of each step,
// then passes the result of the previous step as the input to the next step.
function _uploadFilesContinue(outputId) {
  const outputElement = document.getElementById(outputId);
  const steps = outputElement.steps;

  const next = steps.next(outputElement.lastPromiseValue);
  return Promise.resolve(next.value.promise).then((value) => {
    // Cache the last promise value to make it available to the next
    // step of the generator.
    outputElement.lastPromiseValue = value;
    return next.value.response;
  });
}

/**
 * Generator function which is called between each async step of the upload
 * process.
 * @param {string} inputId Element ID of the input file picker element.
 * @param {string} outputId Element ID of the output display.
 * @return {!Iterable<!Object>} Iterable of next steps.
 */
function* uploadFilesStep(inputId, outputId) {
  const inputElement = document.getElementById(inputId);
  inputElement.disabled = false;

  const outputElement = document.getElementById(outputId);
  outputElement.innerHTML = '';

  const pickedPromise = new Promise((resolve) => {
    inputElement.addEventListener('change', (e) => {
      resolve(e.target.files);
    });
  });

  const cancel = document.createElement('button');
  inputElement.parentElement.appendChild(cancel);
  cancel.textContent = 'Cancel upload';
  const cancelPromise = new Promise((resolve) => {
    cancel.onclick = () => {
      resolve(null);
    };
  });

  // Wait for the user to pick the files.
  const files = yield {
    promise: Promise.race([pickedPromise, cancelPromise]),
    response: {
      action: 'starting',
    }
  };

  cancel.remove();

  // Disable the input element since further picks are not allowed.
  inputElement.disabled = true;

  if (!files) {
    return {
      response: {
        action: 'complete',
      }
    };
  }

  for (const file of files) {
    const li = document.createElement('li');
    li.append(span(file.name, {fontWeight: 'bold'}));
    li.append(span(
        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +
        `last modified: ${
            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :
                                    'n/a'} - `));
    const percent = span('0% done');
    li.appendChild(percent);

    outputElement.appendChild(li);

    const fileDataPromise = new Promise((resolve) => {
      const reader = new FileReader();
      reader.onload = (e) => {
        resolve(e.target.result);
      };
      reader.readAsArrayBuffer(file);
    });
    // Wait for the data to be ready.
    let fileData = yield {
      promise: fileDataPromise,
      response: {
        action: 'continue',
      }
    };

    // Use a chunked sending to avoid message size limits. See b/62115660.
    let position = 0;
    do {
      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);
      const chunk = new Uint8Array(fileData, position, length);
      position += length;

      const base64 = btoa(String.fromCharCode.apply(null, chunk));
      yield {
        response: {
          action: 'append',
          file: file.name,
          data: base64,
        },
      };

      let percentDone = fileData.byteLength === 0 ?
          100 :
          Math.round((position / fileData.byteLength) * 100);
      percent.textContent = `${percentDone}% done`;

    } while (position < fileData.byteLength);
  }

  // All done.
  yield {
    response: {
      action: 'complete',
    }
  };
}

scope.google = scope.google || {};
scope.google.colab = scope.google.colab || {};
scope.google.colab._files = {
  _uploadFiles,
  _uploadFilesContinue,
};
})(self);
</script> 


    Saving kaggle.json to kaggle.json





    {'kaggle.json': b'{"username":"jaewon2do","key":"e52a891c18fd5084ab8f9210e2a9e8f7"}'}




```python
ls -1ha kaggle.json
```

    kaggle.json



```python
!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/

# Permission Warning 방지
!chmod 600 ~/.kaggle/kaggle.json
```


```python
!kaggle competitions download -c playground-series-s3e2
```

    Downloading playground-series-s3e2.zip to /content
      0% 0.00/321k [00:00<?, ?B/s]
    100% 321k/321k [00:00<00:00, 19.4MB/s]



```python
!ls
```

    kaggle.json  playground-series-s3e2.zip  sample_data



```python
!unzip playground-series-s3e2.zip
```

    Archive:  playground-series-s3e2.zip
      inflating: sample_submission.csv   
      inflating: test.csv                
      inflating: train.csv               



```python
# For each id in the test set, you must predict the probability for the target variable stroke.
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

train = pd.read_csv('/content/train.csv')
test = pd.read_csv('/content/test.csv')
```

# 훈련 데이터 전처리


```python
train # hyptertension은 고혈압, avg_glucose_level은 혈당 수치
```





  <div id="df-339a7e8f-c636-4abb-acb1-e616d5fc0bb2">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>id</th>
      <th>gender</th>
      <th>age</th>
      <th>hypertension</th>
      <th>heart_disease</th>
      <th>ever_married</th>
      <th>work_type</th>
      <th>Residence_type</th>
      <th>avg_glucose_level</th>
      <th>bmi</th>
      <th>smoking_status</th>
      <th>stroke</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>Male</td>
      <td>28.0</td>
      <td>0</td>
      <td>0</td>
      <td>Yes</td>
      <td>Private</td>
      <td>Urban</td>
      <td>79.53</td>
      <td>31.1</td>
      <td>never smoked</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>Male</td>
      <td>33.0</td>
      <td>0</td>
      <td>0</td>
      <td>Yes</td>
      <td>Private</td>
      <td>Rural</td>
      <td>78.44</td>
      <td>23.9</td>
      <td>formerly smoked</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2</td>
      <td>Female</td>
      <td>42.0</td>
      <td>0</td>
      <td>0</td>
      <td>Yes</td>
      <td>Private</td>
      <td>Rural</td>
      <td>103.00</td>
      <td>40.3</td>
      <td>Unknown</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>3</td>
      <td>Male</td>
      <td>56.0</td>
      <td>0</td>
      <td>0</td>
      <td>Yes</td>
      <td>Private</td>
      <td>Urban</td>
      <td>64.87</td>
      <td>28.8</td>
      <td>never smoked</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>4</td>
      <td>Female</td>
      <td>24.0</td>
      <td>0</td>
      <td>0</td>
      <td>No</td>
      <td>Private</td>
      <td>Rural</td>
      <td>73.36</td>
      <td>28.8</td>
      <td>never smoked</td>
      <td>0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>15299</th>
      <td>15299</td>
      <td>Female</td>
      <td>22.0</td>
      <td>0</td>
      <td>0</td>
      <td>No</td>
      <td>Govt_job</td>
      <td>Urban</td>
      <td>72.63</td>
      <td>19.5</td>
      <td>never smoked</td>
      <td>0</td>
    </tr>
    <tr>
      <th>15300</th>
      <td>15300</td>
      <td>Female</td>
      <td>46.0</td>
      <td>1</td>
      <td>0</td>
      <td>Yes</td>
      <td>Private</td>
      <td>Urban</td>
      <td>101.19</td>
      <td>32.1</td>
      <td>never smoked</td>
      <td>0</td>
    </tr>
    <tr>
      <th>15301</th>
      <td>15301</td>
      <td>Female</td>
      <td>75.0</td>
      <td>0</td>
      <td>0</td>
      <td>Yes</td>
      <td>Self-employed</td>
      <td>Urban</td>
      <td>87.69</td>
      <td>26.2</td>
      <td>never smoked</td>
      <td>0</td>
    </tr>
    <tr>
      <th>15302</th>
      <td>15302</td>
      <td>Male</td>
      <td>46.0</td>
      <td>0</td>
      <td>0</td>
      <td>Yes</td>
      <td>Private</td>
      <td>Rural</td>
      <td>101.13</td>
      <td>22.5</td>
      <td>Unknown</td>
      <td>0</td>
    </tr>
    <tr>
      <th>15303</th>
      <td>15303</td>
      <td>Female</td>
      <td>14.0</td>
      <td>0</td>
      <td>0</td>
      <td>No</td>
      <td>Private</td>
      <td>Rural</td>
      <td>85.12</td>
      <td>24.7</td>
      <td>never smoked</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>15304 rows × 12 columns</p>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-339a7e8f-c636-4abb-acb1-e616d5fc0bb2')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>

  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-339a7e8f-c636-4abb-acb1-e616d5fc0bb2 button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-339a7e8f-c636-4abb-acb1-e616d5fc0bb2');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>





```python
train.info()
```

    <class 'pandas.core.frame.DataFrame'>
    RangeIndex: 15304 entries, 0 to 15303
    Data columns (total 12 columns):
     #   Column             Non-Null Count  Dtype  
    ---  ------             --------------  -----  
     0   id                 15304 non-null  int64  
     1   gender             15304 non-null  object 
     2   age                15304 non-null  float64
     3   hypertension       15304 non-null  int64  
     4   heart_disease      15304 non-null  int64  
     5   ever_married       15304 non-null  object 
     6   work_type          15304 non-null  object 
     7   Residence_type     15304 non-null  object 
     8   avg_glucose_level  15304 non-null  float64
     9   bmi                15304 non-null  float64
     10  smoking_status     15304 non-null  object 
     11  stroke             15304 non-null  int64  
    dtypes: float64(3), int64(4), object(5)
    memory usage: 1.4+ MB



```python
train = train.drop_duplicates() # 중복값 없음.
train.shape
```




    (15304, 12)




```python
# Dtype이 object인 것은 describe로 단순 통계를 확인할 수 없음. -> unique로 어떤 값을 가지는지 알아볼 것.
for p in train.columns:
    if train[p].dtype == object:
        print("특성 {}는 {}값을 갖는다.".format(p, train[p].unique()))
```

    특성 gender는 ['Male' 'Female' 'Other']값을 갖는다.
    특성 ever_married는 ['Yes' 'No']값을 갖는다.
    특성 work_type는 ['Private' 'Self-employed' 'Govt_job' 'children' 'Never_worked']값을 갖는다.
    특성 Residence_type는 ['Urban' 'Rural']값을 갖는다.
    특성 smoking_status는 ['never smoked' 'formerly smoked' 'Unknown' 'smokes']값을 갖는다.



```python
for p in train.columns:
    if train[p].dtype == object:
        fig = plt.figure()
        sns.countplot(x=p, data = train)
        fig

# 일단 ever_married, residence_type는 레이블 인코딩을 해도 괜찮다.
# gender의 "Other"와 smoking_status의 "Unknown"는 결측값 처리 해야함.
```


    
![png](data_study_4_v2_files/data_study_4_v2_12_0.png)
    



    
![png](data_study_4_v2_files/data_study_4_v2_12_1.png)
    



    
![png](data_study_4_v2_files/data_study_4_v2_12_2.png)
    



    
![png](data_study_4_v2_files/data_study_4_v2_12_3.png)
    



    
![png](data_study_4_v2_files/data_study_4_v2_12_4.png)
    



```python
train.describe()
# age에서의 min값이 0.08 -> 정수로 떨어지지 않는 age 값을 결측값으로 간주하여 처리한다.
```





  <div id="df-9ee3f74d-86eb-40ad-8938-a145d8a6daa4">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>id</th>
      <th>age</th>
      <th>hypertension</th>
      <th>heart_disease</th>
      <th>avg_glucose_level</th>
      <th>bmi</th>
      <th>stroke</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>15304.000000</td>
      <td>15304.000000</td>
      <td>15304.000000</td>
      <td>15304.000000</td>
      <td>15304.000000</td>
      <td>15304.000000</td>
      <td>15304.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>7651.500000</td>
      <td>41.417708</td>
      <td>0.049726</td>
      <td>0.023327</td>
      <td>89.039853</td>
      <td>28.112721</td>
      <td>0.041296</td>
    </tr>
    <tr>
      <th>std</th>
      <td>4418.028595</td>
      <td>21.444673</td>
      <td>0.217384</td>
      <td>0.150946</td>
      <td>25.476102</td>
      <td>6.722315</td>
      <td>0.198981</td>
    </tr>
    <tr>
      <th>min</th>
      <td>0.000000</td>
      <td>0.080000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>55.220000</td>
      <td>10.300000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>3825.750000</td>
      <td>26.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>74.900000</td>
      <td>23.500000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>7651.500000</td>
      <td>43.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>85.120000</td>
      <td>27.600000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>11477.250000</td>
      <td>57.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>96.980000</td>
      <td>32.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>15303.000000</td>
      <td>82.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>267.600000</td>
      <td>80.100000</td>
      <td>1.000000</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-9ee3f74d-86eb-40ad-8938-a145d8a6daa4')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>

  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-9ee3f74d-86eb-40ad-8938-a145d8a6daa4 button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-9ee3f74d-86eb-40ad-8938-a145d8a6daa4');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>




* 값이 두개인 특성은 (int64)hypertension, heart_disease, stroke, (object)ever_married, Residence_type이다.

    -> ever_married, Residence_type는 레이블 인코딩해준다.

    -> work_type는 원핫인코딩해준다.

*  정수로 떨어지지 않는 값을 가진 age, "Other"값을 갖는 gender, "Unknown"값을 갖는 smoking_status를 결측값 처리해야 한다.

* 추가적으로 맥락상 모순되는 값을 갖는 결측값이 존재하는지 확인.

* 데이터 분석에 아무런 영향을 주지 않는 정보 삭제할 것.

인코딩 유형 출처: https://hye-z.tistory.com/m/16


```python
# 수치형 데이터로 처리 가능한 범주형 데이터 : ever_married, Residence_type, work_type
# 수치형 데이터 처리 전 결측치 처리해야하는 데이터 : gender, smoking_status

from sklearn.preprocessing import LabelEncoder

ever_married_answer = train['ever_married'].unique()
encoder = LabelEncoder()
encoder.fit(ever_married_answer)
train['ever_married'] = encoder.transform(train['ever_married'])
print(ever_married_answer, encoder.transform(ever_married_answer))

Residence_type = train['Residence_type'].unique()
encoder = LabelEncoder()
encoder.fit(Residence_type)
train['Residence_type'] = encoder.transform(train['Residence_type'])
print(Residence_type, encoder.transform(Residence_type))

work_type = train['work_type'].unique()
encoder = LabelEncoder()
encoder.fit(work_type)
train['work_type'] = encoder.transform(train['work_type'])
print(work_type, encoder.transform(work_type))

# print("특성 ever_married는 {}값을 갖고 dtype은 {}이다.".format(train.ever_married.unique(), train['ever_married'].dtype))
# print("특성 Residence_type는 {}값을 갖고 dtype은 {}이다.".format(train.Residence_type.unique(), train['Residence_type'].dtype))
```

    ['Yes' 'No'] [1 0]
    ['Urban' 'Rural'] [1 0]
    ['Private' 'Self-employed' 'Govt_job' 'children' 'Never_worked'] [2 3 0 4 1]



```python
work_type_checker = pd.DataFrame(['Private', 'Self-employed', 'Govt_job', 'children', 'Never_worked'], [2, 3, 0, 4, 1], columns = ['work_type'])
work_type_checker
```





  <div id="df-589bdcef-909e-4092-83b1-37fa0b974309">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>work_type</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2</th>
      <td>Private</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Self-employed</td>
    </tr>
    <tr>
      <th>0</th>
      <td>Govt_job</td>
    </tr>
    <tr>
      <th>4</th>
      <td>children</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Never_worked</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-589bdcef-909e-4092-83b1-37fa0b974309')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>

  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-589bdcef-909e-4092-83b1-37fa0b974309 button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-589bdcef-909e-4092-83b1-37fa0b974309');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>





```python
train
```





  <div id="df-c7b8a63f-039d-4338-b2f1-188236836416">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>id</th>
      <th>gender</th>
      <th>age</th>
      <th>hypertension</th>
      <th>heart_disease</th>
      <th>ever_married</th>
      <th>work_type</th>
      <th>Residence_type</th>
      <th>avg_glucose_level</th>
      <th>bmi</th>
      <th>smoking_status</th>
      <th>stroke</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>Male</td>
      <td>28.0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>2</td>
      <td>1</td>
      <td>79.53</td>
      <td>31.1</td>
      <td>never smoked</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>Male</td>
      <td>33.0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>2</td>
      <td>0</td>
      <td>78.44</td>
      <td>23.9</td>
      <td>formerly smoked</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2</td>
      <td>Female</td>
      <td>42.0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>2</td>
      <td>0</td>
      <td>103.00</td>
      <td>40.3</td>
      <td>Unknown</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>3</td>
      <td>Male</td>
      <td>56.0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>2</td>
      <td>1</td>
      <td>64.87</td>
      <td>28.8</td>
      <td>never smoked</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>4</td>
      <td>Female</td>
      <td>24.0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>2</td>
      <td>0</td>
      <td>73.36</td>
      <td>28.8</td>
      <td>never smoked</td>
      <td>0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>15299</th>
      <td>15299</td>
      <td>Female</td>
      <td>22.0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>72.63</td>
      <td>19.5</td>
      <td>never smoked</td>
      <td>0</td>
    </tr>
    <tr>
      <th>15300</th>
      <td>15300</td>
      <td>Female</td>
      <td>46.0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>2</td>
      <td>1</td>
      <td>101.19</td>
      <td>32.1</td>
      <td>never smoked</td>
      <td>0</td>
    </tr>
    <tr>
      <th>15301</th>
      <td>15301</td>
      <td>Female</td>
      <td>75.0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>3</td>
      <td>1</td>
      <td>87.69</td>
      <td>26.2</td>
      <td>never smoked</td>
      <td>0</td>
    </tr>
    <tr>
      <th>15302</th>
      <td>15302</td>
      <td>Male</td>
      <td>46.0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>2</td>
      <td>0</td>
      <td>101.13</td>
      <td>22.5</td>
      <td>Unknown</td>
      <td>0</td>
    </tr>
    <tr>
      <th>15303</th>
      <td>15303</td>
      <td>Female</td>
      <td>14.0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>2</td>
      <td>0</td>
      <td>85.12</td>
      <td>24.7</td>
      <td>never smoked</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>15304 rows × 12 columns</p>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-c7b8a63f-039d-4338-b2f1-188236836416')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>

  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-c7b8a63f-039d-4338-b2f1-188236836416 button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-c7b8a63f-039d-4338-b2f1-188236836416');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>




결측치 유형과 처리 기준 : https://junklee.tistory.com/4

1.  age 결측 데이터 처리


```python
float_age = []

for i in train.index:
    if train.loc[i,'age'] - int(train.loc[i,'age']) > 0:
        float_age.append(i)

old_shape = train.shape[0]
print('train 데이터에서 age 결측치의 비율은 {:.2f}%이다.'.format(len(float_age) / old_shape * 100))

for i in float_age:
    train = train.drop(i, axis=0)

train.reset_index(drop=True, inplace=True)
print("age 결측치 처리 후 데이터의 수는 {}에서 {}로 감소".format(old_shape, train.shape[0]))

train.age = train.age.astype("int")
```

    train 데이터에서 age 결측치의 비율은 2.62%이다.
    age 결측치 처리 후 데이터의 수는 15304에서 14903로 감소


2.  gender 결측 데이터 처리 및 인코딩


```python
other_gender = []

for i in train.index:
    if train.loc[i,"gender"] == "Other":
        other_gender.append(i)

old_shape = train.shape[0]
print('train 데이터에서 gender 결측치의 비율은 {:.2f}%이다.'.format(len(other_gender) / old_shape * 100))

for i in other_gender:
    train = train.drop(i, axis=0)

train.reset_index(drop=True, inplace=True)
print("gender 결측치 처리 후 데이터의 수는 {}에서 {}로 감소".format(old_shape, train.shape[0]))

# gender == "Other" 데이터 삭제 후 레이블 인코딩 진행.
gender = train['gender'].unique()
encoder = LabelEncoder()
encoder.fit(gender)
train['gender'] = encoder.transform(train['gender'])
print(gender, encoder.transform(gender))
```

    train 데이터에서 gender 결측치의 비율은 0.01%이다.
    gender 결측치 처리 후 데이터의 수는 14903에서 14902로 감소
    ['Male' 'Female'] [1 0]


3.  smoking_status 처리 전 맥락 상 결측치 처리


```python
# 세계 결혼 가능 최소 나이 기사 : https://www.segye.com/newsView/20161228001241
# -> 데이터에 국적이 없기 때문에 193개국의 평균 사용 -> 16세 미만 데이터 중 ever_married가 Yes인 경우 제거

missing_married = []
for n in train[(train['age'] < 16) & (train['ever_married'] == 1)].loc[:,:].index:
    missing_married.append(n)

old_shape = train.shape[0]
print('train 데이터에서 나이가 국제 평균 혼인적령보다 낮고 결혼 경험이 있는 데이터의 비율은 {:.2f}%이다.'.format(len(missing_married) / old_shape * 100))

for i in missing_married:
    train = train.drop(i, axis=0)

train.reset_index(drop=True, inplace=True)
print("나이가 국제 평균 혼인적령보다 낮고 결혼 경험이 있는 결측치 처리 후 데이터의 수는 {}에서 {}로 감소".format(old_shape, train.shape[0]))
```

    train 데이터에서 나이가 국제 평균 혼인적령보다 낮고 결혼 경험이 있는 데이터의 비율은 0.02%이다.
    나이가 국제 평균 혼인적령보다 낮고 결혼 경험이 있는 결측치 처리 후 데이터의 수는 14902에서 14899로 감소



```python
# International child labor standards set the minimum age for light work at 13 years and general employment at 15.
# 출처 : https://bluemarblepayroll.com/international-labor-laws-minimum-age-requirements/

missing_children = []
for n in train[(train['age'] < 15) & (train['work_type'] != 4)].loc[:,:].index: # work_type : 4 -> children
    missing_children.append(n)

old_shape = train.shape[0]
print('train 데이터에서 나이가 국제 최소 근로 가능 연령보다 낮고 work_type이 children이 아닌 데이터의 비율은 {:.2f}%이다.'.format(len(missing_children) / old_shape * 100))

for i in missing_children:
    train = train.drop(i, axis=0)

train.reset_index(drop=True, inplace=True)
print("나이가 국제 최소 근로 가능 연령보다 낮고 work_type이 children이 아닌 결측치 처리 후 데이터의 수는 {}에서 {}로 감소".format(old_shape, train.shape[0]))
```

    train 데이터에서 나이가 국제 최소 근로 가능 연령보다 낮고 work_type이 children이 아닌 데이터의 비율은 0.93%이다.
    나이가 국제 최소 근로 가능 연령보다 낮고 work_type이 children이 아닌 결측치 처리 후 데이터의 수는 14899에서 14760로 감소



```python
train_id = train.id
train = train.drop(["id"], axis="columns")
train = train[['gender', 'age', 'hypertension', 'heart_disease', 'ever_married',
       'work_type', 'Residence_type', 'avg_glucose_level', 'bmi',
       'stroke', 'smoking_status']]
```


```python
train.columns
```




    Index(['gender', 'age', 'hypertension', 'heart_disease', 'ever_married',
           'work_type', 'Residence_type', 'avg_glucose_level', 'bmi', 'stroke',
           'smoking_status'],
          dtype='object')




```python
unknown_smoking_index = []

for i in train.index:
    if train.loc[i,"smoking_status"] == "Unknown":
        unknown_smoking_index.append(i)

print('train 데이터에서 smoking_status 결측치의 비율은 {:.2f}%이다.'.format(len(unknown_smoking_index) / train.shape[0] * 100)) # 결측치 데이터가 20% 초과 -> 모델 기반 처리
```

    train 데이터에서 smoking_status 결측치의 비율은 27.62%이다.



```python
# 먼저 랜덤포레스트 분류를 통해서 smoking_status가 unknown인 데이터를 분류한다.
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import GridSearchCV, train_test_split
from sklearn.metrics import accuracy_score

data = train[train['smoking_status'] != 'Unknown'].iloc[:,:-1].to_numpy()
target = train[train['smoking_status'] != 'Unknown'].iloc[:,-1]

train_input, test_input, train_target, test_target = train_test_split(data, target)

dic = {'n_estimators': [100, 200, 300, 400, 500, 600, 700],
       'max_depth' : [4, 5, 6, 7, 8, 9, 10]}

rf = RandomForestClassifier()
gs = GridSearchCV(estimator = rf, param_grid = dic, cv = 5, scoring='accuracy')

gs.fit(train_input, train_target)
```


    ---------------------------------------------------------------------------

    KeyboardInterrupt                         Traceback (most recent call last)

    <ipython-input-24-d073afce9bfb> in <module>
         15 gs = GridSearchCV(estimator = rf, param_grid = dic, cv = 5, scoring='accuracy')
         16 
    ---> 17 gs.fit(train_input, train_target)
    

    /usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_search.py in fit(self, X, y, groups, **fit_params)
        889                 return results
        890 
    --> 891             self._run_search(evaluate_candidates)
        892 
        893             # multimetric is determined here because in the case of a callable


    /usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_search.py in _run_search(self, evaluate_candidates)
       1390     def _run_search(self, evaluate_candidates):
       1391         """Search all candidates in param_grid"""
    -> 1392         evaluate_candidates(ParameterGrid(self.param_grid))
       1393 
       1394 


    /usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_search.py in evaluate_candidates(candidate_params, cv, more_results)
        836                     )
        837 
    --> 838                 out = parallel(
        839                     delayed(_fit_and_score)(
        840                         clone(base_estimator),


    /usr/local/lib/python3.8/dist-packages/joblib/parallel.py in __call__(self, iterable)
       1086                 self._iterating = self._original_iterator is not None
       1087 
    -> 1088             while self.dispatch_one_batch(iterator):
       1089                 pass
       1090 


    /usr/local/lib/python3.8/dist-packages/joblib/parallel.py in dispatch_one_batch(self, iterator)
        899                 return False
        900             else:
    --> 901                 self._dispatch(tasks)
        902                 return True
        903 


    /usr/local/lib/python3.8/dist-packages/joblib/parallel.py in _dispatch(self, batch)
        817         with self._lock:
        818             job_idx = len(self._jobs)
    --> 819             job = self._backend.apply_async(batch, callback=cb)
        820             # A job can complete so quickly than its callback is
        821             # called before we get here, causing self._jobs to


    /usr/local/lib/python3.8/dist-packages/joblib/_parallel_backends.py in apply_async(self, func, callback)
        206     def apply_async(self, func, callback=None):
        207         """Schedule a func to be run"""
    --> 208         result = ImmediateResult(func)
        209         if callback:
        210             callback(result)


    /usr/local/lib/python3.8/dist-packages/joblib/_parallel_backends.py in __init__(self, batch)
        595         # Don't delay the application, to avoid keeping the input
        596         # arguments in memory
    --> 597         self.results = batch()
        598 
        599     def get(self):


    /usr/local/lib/python3.8/dist-packages/joblib/parallel.py in __call__(self)
        286         # change the default number of processes to -1
        287         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    --> 288             return [func(*args, **kwargs)
        289                     for func, args, kwargs in self.items]
        290 


    /usr/local/lib/python3.8/dist-packages/joblib/parallel.py in <listcomp>(.0)
        286         # change the default number of processes to -1
        287         with parallel_backend(self._backend, n_jobs=self._n_jobs):
    --> 288             return [func(*args, **kwargs)
        289                     for func, args, kwargs in self.items]
        290 


    /usr/local/lib/python3.8/dist-packages/sklearn/utils/fixes.py in __call__(self, *args, **kwargs)
        214     def __call__(self, *args, **kwargs):
        215         with config_context(**self.config):
    --> 216             return self.function(*args, **kwargs)
        217 
        218 


    /usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)
        678             estimator.fit(X_train, **fit_params)
        679         else:
    --> 680             estimator.fit(X_train, y_train, **fit_params)
        681 
        682     except Exception:


    /usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_forest.py in fit(self, X, y, sample_weight)
        437                 random_state.randint(MAX_INT, size=len(self.estimators_))
        438 
    --> 439             trees = [
        440                 self._make_estimator(append=False, random_state=random_state)
        441                 for i in range(n_more_estimators)


    /usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_forest.py in <listcomp>(.0)
        438 
        439             trees = [
    --> 440                 self._make_estimator(append=False, random_state=random_state)
        441                 for i in range(n_more_estimators)
        442             ]


    /usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_base.py in _make_estimator(self, append, random_state)
        156         sub-estimators.
        157         """
    --> 158         estimator = clone(self.base_estimator_)
        159         estimator.set_params(**{p: getattr(self, p) for p in self.estimator_params})
        160 


    /usr/local/lib/python3.8/dist-packages/sklearn/base.py in clone(estimator, safe)
         86         new_object_params[name] = clone(param, safe=False)
         87     new_object = klass(**new_object_params)
    ---> 88     params_set = new_object.get_params(deep=False)
         89 
         90     # quick sanity check of the parameters of the clone


    /usr/local/lib/python3.8/dist-packages/sklearn/base.py in get_params(self, deep)
        207         """
        208         out = dict()
    --> 209         for key in self._get_param_names():
        210             value = getattr(self, key)
        211             if deep and hasattr(value, "get_params"):


    /usr/local/lib/python3.8/dist-packages/sklearn/base.py in _get_param_names(cls)
        172         # introspect the constructor arguments to find the model parameters
        173         # to represent
    --> 174         init_signature = inspect.signature(init)
        175         # Consider the constructor parameters excluding 'self'
        176         parameters = [


    /usr/lib/python3.8/inspect.py in signature(obj, follow_wrapped)
       3103 def signature(obj, *, follow_wrapped=True):
       3104     """Get a signature object for the passed callable."""
    -> 3105     return Signature.from_callable(obj, follow_wrapped=follow_wrapped)
       3106 
       3107 


    /usr/lib/python3.8/inspect.py in from_callable(cls, obj, follow_wrapped)
       2852     def from_callable(cls, obj, *, follow_wrapped=True):
       2853         """Constructs Signature for the given callable object."""
    -> 2854         return _signature_from_callable(obj, sigcls=cls,
       2855                                         follow_wrapper_chains=follow_wrapped)
       2856 


    /usr/lib/python3.8/inspect.py in _signature_from_callable(obj, follow_wrapper_chains, skip_bound_arg, sigcls)
       2302         # If it's a pure Python function, or an object that is duck type
       2303         # of a Python function (Cython functions, for instance), then:
    -> 2304         return _signature_from_function(sigcls, obj,
       2305                                         skip_bound_arg=skip_bound_arg)
       2306 


    /usr/lib/python3.8/inspect.py in _signature_from_function(cls, func, skip_bound_arg)
       2195 
       2196         annotation = annotations.get(name, _empty)
    -> 2197         parameters.append(Parameter(name, annotation=annotation,
       2198                                     kind=_KEYWORD_ONLY,
       2199                                     default=default))


    /usr/lib/python3.8/inspect.py in __init__(self, name, kind, default, annotation)
       2525             raise ValueError('{!r} is not a valid parameter name'.format(name))
       2526 
    -> 2527         self._name = name
       2528 
       2529     def __reduce__(self):


    KeyboardInterrupt: 



```python
rf = RandomForestClassifier(oob_score=True, n_estimators=gs.best_params_['n_estimators'], max_depth=gs.best_params_['max_depth'])
rf.fit(train_input,train_target)
pred = rf.predict(test_input)
accuracy = accuracy_score(test_target, pred)
print("랜덤 포레스트 분류 정확도는 {}이다.".format(accuracy))

# 정확도가 너무 낮다. -> 정확도를 높이기 위해서 분석할 필요가 있다.
```

* 마지막 결측치인 "Unknown"데이터를 분류하기 위해서 랜덤포레스트 분류 모델을 돌렸으나 정확도가 너무 낮다.

    -> "Unknown"을 분류하기 이전에 EDA 분석 및 이상치 처리 진행

# "Unknown"을 분류하기 이전 EDA 분석과 랜덤포레스트 분류

EDA란 ?

(출처: https://jalynne-kim.medium.com/%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B6%84%EC%84%9D-%EA%B8%B0%EC%B4%88-eda%EC%9D%98-%EA%B0%9C%EB%85%90%EA%B3%BC-%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B6%84%EC%84%9D-%EC%9E%98-%ED%95%98%EB%8A%94-%EB%B2%95-a3cac2cc5ebc)


```python
known = train[train['smoking_status'] != 'Unknown']
known.reset_index(drop=True, inplace=True)

unknown = train[train['smoking_status'] == 'Unknown']
unknown.reset_index(drop=True, inplace=True)

known
```





  <div id="df-6f10d2be-c2f1-43b7-8a96-0e31c3640cdd">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>gender</th>
      <th>age</th>
      <th>hypertension</th>
      <th>heart_disease</th>
      <th>ever_married</th>
      <th>work_type</th>
      <th>Residence_type</th>
      <th>avg_glucose_level</th>
      <th>bmi</th>
      <th>stroke</th>
      <th>smoking_status</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>28</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>2</td>
      <td>1</td>
      <td>79.53</td>
      <td>31.1</td>
      <td>0</td>
      <td>never smoked</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>33</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>2</td>
      <td>0</td>
      <td>78.44</td>
      <td>23.9</td>
      <td>0</td>
      <td>formerly smoked</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1</td>
      <td>56</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>2</td>
      <td>1</td>
      <td>64.87</td>
      <td>28.8</td>
      <td>0</td>
      <td>never smoked</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0</td>
      <td>24</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>2</td>
      <td>0</td>
      <td>73.36</td>
      <td>28.8</td>
      <td>0</td>
      <td>never smoked</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0</td>
      <td>53</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>2</td>
      <td>0</td>
      <td>88.97</td>
      <td>25.3</td>
      <td>0</td>
      <td>never smoked</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>10678</th>
      <td>0</td>
      <td>32</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>2</td>
      <td>1</td>
      <td>75.06</td>
      <td>32.4</td>
      <td>0</td>
      <td>smokes</td>
    </tr>
    <tr>
      <th>10679</th>
      <td>0</td>
      <td>17</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>2</td>
      <td>0</td>
      <td>77.65</td>
      <td>24.8</td>
      <td>0</td>
      <td>smokes</td>
    </tr>
    <tr>
      <th>10680</th>
      <td>0</td>
      <td>22</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>72.63</td>
      <td>19.5</td>
      <td>0</td>
      <td>never smoked</td>
    </tr>
    <tr>
      <th>10681</th>
      <td>0</td>
      <td>46</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>2</td>
      <td>1</td>
      <td>101.19</td>
      <td>32.1</td>
      <td>0</td>
      <td>never smoked</td>
    </tr>
    <tr>
      <th>10682</th>
      <td>0</td>
      <td>75</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>3</td>
      <td>1</td>
      <td>87.69</td>
      <td>26.2</td>
      <td>0</td>
      <td>never smoked</td>
    </tr>
  </tbody>
</table>
<p>10683 rows × 11 columns</p>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-6f10d2be-c2f1-43b7-8a96-0e31c3640cdd')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>

  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-6f10d2be-c2f1-43b7-8a96-0e31c3640cdd button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-6f10d2be-c2f1-43b7-8a96-0e31c3640cdd');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>





```python
fig, ax = plt.subplots(1,2,figsize=(10,8), constrained_layout = True)

sns.countplot(x='smoking_status', data=known, ax = ax[0])
ax[0].set_title("known datas' smoking_status countplot")

known['smoking_status'].value_counts().plot.pie(explode = [0, 0.08, 0.08], autopct='%.2f%%', ax=ax[1], shadow=True)
ax[1].set_title("known datas' smoking_status pie plot")
ax[1].set_ylabel("")
```




    Text(0, 0.5, '')




    
![png](data_study_4_v2_files/data_study_4_v2_37_1.png)
    


* 데이터 자체가 never smoked, formerly smoked, smokes 순으로 많음.
* known 데이터의 smoking_status의 비율과 큰 차이가 나지 않는다면 분류에 유효하지 않은 특성으로 간주.

    -> 범주형 특성에 대한 비율에 대해서 임의로 허용 오차를 5% 이내로 설정.

    ***-> 즉 never smoked가 53.18 ~ 63.18%, formerly smoked가 16.76 ~ 26.76%, smokes가 15.06 ~ 25.06% 안에 있으면 유효한 특성이 아니다.***(표본 데이터의 경향을 그대로 따라가기 때문)
    
   ***-> 허용 오차를 포함한 데이터 분석에 적용되는 통계학 공부가 필요한 부분.***


```python
sns.countplot(x='gender', data=known) # 데이터 자체가 여성이 더 많다. -> 성별에 따른 비교가 어렵다. 남녀 각각의 흡연 경향을 알아봐야함.
```




    <matplotlib.axes._subplots.AxesSubplot at 0x7f6bebd96eb0>




    
![png](data_study_4_v2_files/data_study_4_v2_39_1.png)
    



```python
fig, ax = plt.subplots(1,2,figsize=(10,15), constrained_layout = True)

known[known['gender'] == 0]['smoking_status'].value_counts().plot.pie(explode = [0, 0.08, 0.08], autopct='%.2f%%', ax=ax[0], shadow=True)
ax[0].set_title("female datas' smoking_status pie plot")
ax[0].set_ylabel("")

known[known['gender'] == 1]['smoking_status'].value_counts().plot.pie(explode = [0, 0.08, 0.08], autopct='%.2f%%', ax=ax[1], shadow=True)
ax[1].set_title("male datas' smoking_status pie plot")
ax[1].set_ylabel("")
```




    Text(0, 0.5, '')




    
![png](data_study_4_v2_files/data_study_4_v2_40_1.png)
    


* 여자가 흡연 무경험자의 비율이 더 높다.

* 그러나 흡연 경험 유무 자체를 놓고 본다면 남성의 경우가 흡연할 확률이 더 높다.

    **-> male 데이터와 모집단 데이터의 never smoked와의 비율 차이가 5% 이상 나므로 분류에 쓰기 좋다.**


```python
fig, ax = plt.subplots(2,2, figsize=(15,10), constrained_layout = True)

sns.kdeplot(known['age'], shade = True, label="known", ax = ax[0,0])
sns.kdeplot(known[known['smoking_status'] == 'never smoked']['age'], shade = True, label='never smoked', ax = ax[0,0])
ax[0,0].set_title("comparing age data between known data and never smoked data")
ax[0,0].legend()

sns.kdeplot(known['age'], shade = True, label="known", ax = ax[0,1])
sns.kdeplot(known[known['smoking_status'] == 'formerly smoked']['age'], shade = True, label='formerly smoked', ax = ax[0,1])
ax[0,1].set_title("comparing age data between known data and formerly smoked data")
ax[0,1].legend()

sns.kdeplot(known['age'], shade = True, label="known", ax = ax[1,0])
sns.kdeplot(known[known['smoking_status'] == 'smokes']['age'], shade = True, label='smokes', ax = ax[1,0])
ax[1,0].set_title("comparing age data between known data and smokes data")
ax[1,0].legend()

sns.kdeplot(known[known['smoking_status'] == 'formerly smoked']['age'], shade = True, label="never smoked", ax = ax[1,1])
sns.kdeplot(known[known['smoking_status'] == 'smokes']['age'], shade = True, label='smokes', ax = ax[1,1])
ax[1,1].set_title("comparing age data between never smoked data and smokes data")
ax[1,1].legend()
```




    <matplotlib.legend.Legend at 0x7f6be73a05b0>




    
![png](data_study_4_v2_files/data_study_4_v2_42_1.png)
    


* never smoked 데이터는 전체 known 데이터와 거의 나이대 분포가 유사하다.
* formerly smoked 데이터는 전체 known 데이터보다 50대 이상의 나이대에 분포가 많다.
* smokes 데이터는 전체 known 데이터보다 20대에서 50대 사이의 나이대에 분포가 많다.

    -> 시각화한 결과를 직관적으로 판단하였을 때 smoking_status 분류에 쓰기 좋아보임.


    But, 정확한 판단 기준에 대해서 공부할 필요가 있다.
    예를 들어 어떤 두 커널 밀도 그래프가 각각 모양 자체는 큰 차이가 없어 보여도
    겹치지 않는 부분을 적분하였을 때 어느정도 차이가 나면 분류에 쓰일 수 있을 거 같다는 생각이 들기 때문


```python
sns.countplot(x='hypertension', data=known)
```




    <matplotlib.axes._subplots.AxesSubplot at 0x7f6be731a3a0>




    
![png](data_study_4_v2_files/data_study_4_v2_44_1.png)
    



```python
fig, ax = plt.subplots(1,2,figsize=(10,10), constrained_layout = True)

known[known['hypertension'] == 0]['smoking_status'].value_counts().plot.pie(explode = [0,0.08,0.08], autopct='%.1f%%', ax = ax[0])
ax[0].set_title("hypertension 0 - smoking_status pie plot")
ax[0].set_ylabel("")

known[known['hypertension'] == 1]['smoking_status'].value_counts().plot.pie(explode = [0,0.08,0.08], autopct='%.1f%%', ax = ax[1])
ax[1].set_title("hypertension 1 - smoking_status pie plot")
ax[1].set_ylabel("")
```




    Text(0, 0.5, '')




    
![png](data_study_4_v2_files/data_study_4_v2_45_1.png)
    


* 데이터 자체가 고혈압이 없는 사람이 더 많다.

* But, 고혈압 여부에 따른 흡연 양상이 큰 차이가 없다.

    **-> hypertension의 각 데이터와 모집단 데이터의 특성과의 각각의 비율 차이가 5% 이내에서 나므로 분류에 유효하지 않다.**


```python
sns.countplot(x='heart_disease', data=known) # 데이터 자체가 심장병이 없는 사람이 더 많다.
```




    <matplotlib.axes._subplots.AxesSubplot at 0x7f6be94edf40>




    
![png](data_study_4_v2_files/data_study_4_v2_47_1.png)
    



```python
fig, ax = plt.subplots(1,2,figsize=(10,10), constrained_layout = True)

known[known['heart_disease'] == 0]['smoking_status'].value_counts().plot.pie(explode = [0, 0.08, 0.08], autopct='%.1f%%', ax = ax[0])
ax[0].set_title("heart_disease 0 - smoking_status pie plot")
ax[0].set_ylabel("")

known[known['heart_disease'] == 1]['smoking_status'].value_counts().plot.pie(explode = [0, 0.08, 0.08], autopct='%.1f%%', ax = ax[1])
ax[1].set_title("heart_disease 1 - smoking_status pie plot")
ax[1].set_ylabel("")
```




    Text(0, 0.5, '')




    
![png](data_study_4_v2_files/data_study_4_v2_48_1.png)
    


* 심장병을 앓고 있는 사람이 심장병을 앓고 있지 않는 사람보다 이전에 흡연했을 확률이 높다.

    **-> heart_disease 1 데이터와 표본 데이터의 never smoked, formerly smoked와의 비율 차이가 5% 이상 나므로 분류에 쓰기 좋다.**


```python
sns.countplot(x='ever_married', data=known) # 전체 데이터에서 결혼한 사람이 더 많다.
```




    <matplotlib.axes._subplots.AxesSubplot at 0x7f6be5a29940>




    
![png](data_study_4_v2_files/data_study_4_v2_50_1.png)
    



```python
fig, ax = plt.subplots(1,2,figsize=(10,10), constrained_layout = True)

known[known['ever_married'] == 0]['smoking_status'].value_counts().plot.pie(explode = [0, 0.08, 0.08], autopct='%.1f%%', ax = ax[0])
ax[0].set_title("ever_married 0 - smoking_status pie plot")
ax[0].set_ylabel("")

known[known['ever_married'] == 1]['smoking_status'].value_counts().plot.pie(explode = [0, 0.08, 0.08], autopct='%.1f%%', ax = ax[1])
ax[1].set_title("ever_married 1 - smoking_status pie plot")
ax[1].set_ylabel("")
```




    Text(0, 0.5, '')




    
![png](data_study_4_v2_files/data_study_4_v2_51_1.png)
    


* 결혼을 하고나서 흡연 경험이 더 많았다.

    **-> ever_married 0 데이터와 표본 데이터의 never smoked, formerly smoked와의 비율 차이가 5% 이상 나므로 분류에 쓰기 좋다.**


```python
work_type_checker
```





  <div id="df-33ead314-d932-4556-b3a4-66b9893a7416">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>work_type</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2</th>
      <td>Private</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Self-employed</td>
    </tr>
    <tr>
      <th>0</th>
      <td>Govt_job</td>
    </tr>
    <tr>
      <th>4</th>
      <td>children</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Never_worked</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-33ead314-d932-4556-b3a4-66b9893a7416')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>

  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-33ead314-d932-4556-b3a4-66b9893a7416 button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-33ead314-d932-4556-b3a4-66b9893a7416');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>





```python
fig, ax = plt.subplots(1,2,figsize=(10,8), constrained_layout = True)

sns.countplot(x='work_type', data=known, ax = ax[0])

known['work_type'].value_counts().plot.pie(explode = [0, 0.1, 0.1, 0.5, 0.5], autopct='%.2f%%', ax=ax[1], shadow=True)
ax[1].set_ylabel("")

print("work_type 1의 데이터 갯수는 {}이다.".format(train[train['work_type'] == 1].shape[0]))
print("work_type 4의 데이터 갯수는 {}이다.".format(train[train['work_type'] == 4].shape[0]))
```

    work_type 1의 데이터 갯수는 25이다.
    work_type 4의 데이터 갯수는 1641이다.



    
![png](data_study_4_v2_files/data_study_4_v2_54_1.png)
    


허용 오차를 고려하기 전에 특성에 의해 분류된 표본의 크기도 고려해야할 것 같다.

왜냐하면 표본의 모집단의 대부분을 차지하는 경우에는 모집단의 경향을 따라갈 수 밖에 없기 때문.

결론적으로 또 통개학 공부가 필요한 부분.


```python
fig, ax = plt.subplots(3,2,figsize=(10,10), constrained_layout = True)

known[known['work_type'] == 0]['smoking_status'].value_counts().plot.pie(explode = [0, 0.08, 0.08], autopct='%.1f%%', ax = ax[0,0])
ax[0,0].set_title("work_type 0 - smoking_status pie plot")
ax[0,0].set_ylabel("")

known[known['work_type'] == 1]['smoking_status'].value_counts().plot.pie(explode = [0, 0.08], autopct='%.1f%%', ax = ax[0,1])
ax[0,1].set_title("work_type 1 - smoking_status pie plot")
ax[0,1].set_ylabel("")

known[known['work_type'] == 2]['smoking_status'].value_counts().plot.pie(explode = [0, 0.08, 0.08], autopct='%.1f%%', ax = ax[1,0])
ax[1,0].set_title("work_type 2 - smoking_status pie plot")
ax[1,0].set_ylabel("")

known[known['work_type'] == 3]['smoking_status'].value_counts().plot.pie(explode = [0, 0.08, 0.08], autopct='%.1f%%', ax = ax[1,1])
ax[1,1].set_title("work_type 3 - smoking_status pie plot")
ax[1,1].set_ylabel("")

known[known['work_type'] == 4]['smoking_status'].value_counts().plot.pie(explode = [0, 0.08, 0.08], autopct='%.1f%%', ax = ax[2,0])
ax[2,0].set_title("work_type 4 - smoking_status pie plot")
ax[2,0].set_ylabel("")

ax[2,1].axis('off')
```




    (0.0, 1.0, 0.0, 1.0)




    
![png](data_study_4_v2_files/data_study_4_v2_56_1.png)
    


**-> work_type 1, 4 데이터와 표본 데이터의 각 특성 값과의 비율 차이가 5% 이상 나므로 분류에 쓰기 좋다.**

**-> work_type 3 데이터와 표본 데이터의 formerly smoked, smokes와의 비율 차이가 5% 이상 나므로 분류에 쓰기 좋다.**


```python
fig, ax = plt.subplots(1,2,figsize=(10,10), constrained_layout = True)

sns.countplot(x='Residence_type', data=known, ax = ax[0])

known['Residence_type'].value_counts().plot.pie(explode = [0, 0.1], autopct='%.2f%%', ax=ax[1], shadow=True)
ax[1].set_ylabel("")

# 각 특성값에 따른 흡연 분포가 모집단을 따라갈 것 같음.
```




    Text(0, 0.5, '')




    
![png](data_study_4_v2_files/data_study_4_v2_58_1.png)
    



```python
fig, ax = plt.subplots(1,2,figsize=(10,10), constrained_layout = True)

known[known['Residence_type'] == 0]['smoking_status'].value_counts().plot.pie(explode = [0, 0.08, 0.08], autopct='%.1f%%', ax = ax[0])
ax[0].set_title("ever_married 0 - smoking_status pie plot")
ax[0].set_ylabel("")

known[known['Residence_type'] == 1]['smoking_status'].value_counts().plot.pie(explode = [0, 0.08, 0.08], autopct='%.1f%%', ax = ax[1])
ax[1].set_title("ever_married 1 - smoking_status pie plot")
ax[1].set_ylabel("")
```




    Text(0, 0.5, '')




    
![png](data_study_4_v2_files/data_study_4_v2_59_1.png)
    


**-> Residence_type의 각 데이터와 모집단 데이터의 특성과의 각각의 비율 차이가 5% 이내에서 나므로 분류에 유효하지 않다.**


```python
fig, ax = plt.subplots(2,2, figsize=(15,10), constrained_layout = True)

sns.kdeplot(known['avg_glucose_level'], shade = True, label="known", ax = ax[0,0])
sns.kdeplot(known[known['smoking_status'] == 'never smoked']['avg_glucose_level'], shade = True, label='never smoked', ax = ax[0,0])
ax[0,0].set_title("comparing avg_glucose_level data between known data and never smoked data")
ax[0,0].legend()

sns.kdeplot(known['avg_glucose_level'], shade = True, label="known", ax = ax[0,1])
sns.kdeplot(known[known['smoking_status'] == 'formerly smoked']['avg_glucose_level'], shade = True, label='formerly smoked', ax = ax[0,1])
ax[0,1].set_title("comparing avg_glucose_level data between known data and formerly smoked data")
ax[0,1].legend()

sns.kdeplot(known['avg_glucose_level'], shade = True, label="known", ax = ax[1,0])
sns.kdeplot(known[known['smoking_status'] == 'smokes']['avg_glucose_level'], shade = True, label='smokes', ax = ax[1,0])
ax[1,0].set_title("comparing avg_glucose_level data between known data and smokes data")
ax[1,0].legend()

sns.kdeplot(known[known['smoking_status'] == 'never smoked']['avg_glucose_level'], shade = True, label="never smoked", ax = ax[1,1])
sns.kdeplot(known[known['smoking_status'] == 'smokes']['avg_glucose_level'], shade = True, label='smokes', ax = ax[1,1])
ax[1,1].set_title("comparing avg_glucose_level data between never smoked data and smokes data")
ax[1,1].legend()
```




    <matplotlib.legend.Legend at 0x7f6be56296a0>




    
![png](data_study_4_v2_files/data_study_4_v2_61_1.png)
    


* 나이 데이터와 다르게 혈당 수치는 흡연 여부에 따른 kdeplot의 모양과 적분값이 큰 차이를 보이진 않았다.

    **-> smoking_status 분류에 유효해보이지 않는다.**


```python
fig, ax = plt.subplots(2,2, figsize=(15,10), constrained_layout = True)

sns.kdeplot(known['bmi'], shade = True, label="known", ax = ax[0,0])
sns.kdeplot(known[known['smoking_status'] == 'never smoked']['bmi'], shade = True, label='never smoked', ax = ax[0,0])
ax[0,0].set_title("comparing bmi data between known data and never smoked data")
ax[0,0].legend()

sns.kdeplot(known['bmi'], shade = True, label="known", ax = ax[0,1])
sns.kdeplot(known[known['smoking_status'] == 'formerly smoked']['bmi'], shade = True, label='formerly smoked', ax = ax[0,1])
ax[0,1].set_title("comparing bmi data between known data and formerly smoked data")
ax[0,1].legend()

sns.kdeplot(known['bmi'], shade = True, label="known", ax = ax[1,0])
sns.kdeplot(known[known['smoking_status'] == 'smokes']['bmi'], shade = True, label='smokes', ax = ax[1,0])
ax[1,0].set_title("comparing bmi data between known data and smokes data")
ax[1,0].legend()

sns.kdeplot(known[known['smoking_status'] == 'formerly smoked']['bmi'], shade = True, label="never smoked", ax = ax[1,1])
sns.kdeplot(known[known['smoking_status'] == 'smokes']['bmi'], shade = True, label='smokes', ax = ax[1,1])
ax[1,1].set_title("comparing bmi data between never smoked data and smokes data")
ax[1,1].legend()
```




    <matplotlib.legend.Legend at 0x7f6be58d2d30>




    
![png](data_study_4_v2_files/data_study_4_v2_63_1.png)
    


* 혈당 데이터와 비슷하게 bmi 데이터도 그래프의 모양과 크기에 대해서는 큰 차이를 보이진 않았다.

    **-> smoking_status 분류에 유효해보이지 않는다.**


```python
sns.countplot(x='stroke', data=known) # 전체 데이터에서 뇌졸중에 걸리지 않은 데이터가 더 많았다.
```




    <matplotlib.axes._subplots.AxesSubplot at 0x7f6be58c51f0>




    
![png](data_study_4_v2_files/data_study_4_v2_65_1.png)
    



```python
fig, ax = plt.subplots(1,2,figsize=(10,10), constrained_layout = True)

known[known['stroke'] == 0]['smoking_status'].value_counts().plot.pie(explode = [0, 0.08, 0.08], autopct='%.1f%%', ax = ax[0])
ax[0].set_title("stroke 0 - smoking_status pie plot")
ax[0].set_ylabel("")

known[known['stroke'] == 1]['smoking_status'].value_counts().plot.pie(explode = [0, 0.08, 0.08], autopct='%.1f%%', ax = ax[1])
ax[1].set_title("stroke 1 - smoking_status pie plot")
ax[1].set_ylabel("")
```




    Text(0, 0.5, '')




    
![png](data_study_4_v2_files/data_study_4_v2_66_1.png)
    


**-> stroke 1 데이터와 표본 데이터의 never smoked, formerly smoked와의 비율 차이가 5% 이상 나므로 분류에 쓰기 좋다.**


 ***허용오차 5%에서 판단한 smoking_status 분류 특성:***

'gender', 'age', 'heart_disease', 'ever_married', 'work_type', 'stroke', 'smoking_status'


```python
# test_index = []

# for i in known.index:
#    if known.loc[i,'gender'] == 1 or known.loc[i,'heart_disease'] == 1 or known.loc[i,'ever_married'] == 0 or known.loc[i,'work_type'] in [1,3,4] or known.loc[i,'stroke'] == 1:
#        test_index.append(i)

# len(set(test_index))
```


```python
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import GridSearchCV, train_test_split
from sklearn.metrics import accuracy_score

data = known.loc[:, ['gender', 'age', 'heart_disease', 'ever_married', 'work_type', 'stroke']].to_numpy()
target = known.loc[:, 'smoking_status']

train_input, test_input, train_target, test_target = train_test_split(data, target)

dic = {'n_estimators': [100, 200, 300, 400, 500, 600, 700],
       'max_depth' : [4, 5, 6, 7, 8, 9, 10]}

rf = RandomForestClassifier()
gs = GridSearchCV(estimator = rf, param_grid = dic, cv = 5, scoring='accuracy')

gs.fit(train_input, train_target)
```




    GridSearchCV(cv=5, estimator=RandomForestClassifier(),
                 param_grid={'max_depth': [4, 5, 6, 7, 8, 9, 10],
                             'n_estimators': [100, 200, 300, 400, 500, 600, 700]},
                 scoring='accuracy')




```python
rf = RandomForestClassifier(oob_score=True, n_estimators=gs.best_params_['n_estimators'], max_depth=gs.best_params_['max_depth'])
rf.fit(train_input,train_target)
pred = rf.predict(test_input)
accuracy = accuracy_score(test_target, pred)
print("랜덤 포레스트 분류 정확도는 {}이다.".format(accuracy))

# 나름대로 EDA 분석도 해보았고 그 결과 'gender', 'age', 'heart_disease', 'ever_married', 'work_type', 'stroke' 특성만 돌려봤는데도 정확도가 거의 그대로였다.
# 그래서 모델을 돌릴 때 일부러 특성 갯수를 더 줄여가면서 돌렸는데도 그대로였다. 'age', 'work_type'만 돌렸는데도 그렇게 나왔다.
# 그래서 데이터를 특정 기준을 삼아 추출한 뒤에 모델을 돌려줘야겠다는 생각까지 들었다.
# gender 1, age All, heart_disease 1, ever_married 0, work_type 1, work_type 3, work_type 4, stroke 1에 해당하는 합집합을 돌려봄.
# 기준은 시각화했을 때 모집단의 파이플롯과 차이가 직관적으로 많이 나 보이는 것.
# 그러나 이것도 오히려 정확도가 더 떨어짐.
```

    랜덤 포레스트 분류 정확도는 0.572070385623362이다.


# 딥러닝 기반의 datawig 라이브러리 사용

(출처 : https://blog.naver.com/PostView.naver?blogId=dalgoon02121&logNo=222482929265&categoryNo=33&parentCategoryNo=0&viewDate=&currentPage=1&postListTopCurrentPage=1&from=postView)


```python
!pip install datawig
```

    Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
    Collecting datawig
      Downloading datawig-0.2.0.tar.gz (61 kB)
    [2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m61.5/61.5 KB[0m [31m3.2 MB/s[0m eta [36m0:00:00[0m
    [?25h  Preparing metadata (setup.py) ... [?25l[?25hdone
    Collecting scikit-learn[alldeps]==0.22.1
      Downloading scikit_learn-0.22.1-cp38-cp38-manylinux1_x86_64.whl (7.0 MB)
    [2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m7.0/7.0 MB[0m [31m50.4 MB/s[0m eta [36m0:00:00[0m
    [?25hCollecting typing==3.6.6
      Downloading typing-3.6.6-py3-none-any.whl (25 kB)
    Collecting pandas==0.25.3
      Downloading pandas-0.25.3-cp38-cp38-manylinux1_x86_64.whl (10.4 MB)
    [2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m10.4/10.4 MB[0m [31m55.6 MB/s[0m eta [36m0:00:00[0m
    [?25hCollecting mxnet==1.4.0
      Downloading mxnet-1.4.0-py2.py3-none-manylinux1_x86_64.whl (29.6 MB)
    [2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m29.6/29.6 MB[0m [31m26.0 MB/s[0m eta [36m0:00:00[0m
    [?25hRequirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.8/dist-packages (from mxnet==1.4.0->datawig) (2.25.1)
    Collecting numpy<1.15.0,>=1.8.2
      Downloading numpy-1.14.6.zip (4.9 MB)
    [2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m4.9/4.9 MB[0m [31m91.6 MB/s[0m eta [36m0:00:00[0m
    [?25h  Preparing metadata (setup.py) ... [?25l[?25hdone
    Collecting graphviz<0.9.0,>=0.8.1
      Downloading graphviz-0.8.4-py2.py3-none-any.whl (16 kB)
    Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.8/dist-packages (from pandas==0.25.3->datawig) (2022.7)
    Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.8/dist-packages (from pandas==0.25.3->datawig) (2.8.2)
    Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn[alldeps]==0.22.1->datawig) (1.2.0)
    Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn[alldeps]==0.22.1->datawig) (1.7.3)
    Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.6.1->pandas==0.25.3->datawig) (1.15.0)
    Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20.0->mxnet==1.4.0->datawig) (2.10)
    Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20.0->mxnet==1.4.0->datawig) (2022.12.7)
    Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20.0->mxnet==1.4.0->datawig) (4.0.0)
    Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20.0->mxnet==1.4.0->datawig) (1.24.3)
    Collecting scipy>=0.17.0
      Downloading scipy-1.10.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)
    [2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m34.5/34.5 MB[0m [31m21.9 MB/s[0m eta [36m0:00:00[0m
    [?25h  Downloading scipy-1.9.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (33.8 MB)
    [2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m33.8/33.8 MB[0m [31m11.8 MB/s[0m eta [36m0:00:00[0m
    [?25h  Downloading scipy-1.9.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (33.8 MB)
    [2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m33.8/33.8 MB[0m [31m31.7 MB/s[0m eta [36m0:00:00[0m
    [?25h  Downloading scipy-1.9.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.4 MB)
    [2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m43.4/43.4 MB[0m [31m12.4 MB/s[0m eta [36m0:00:00[0m
    [?25h  Downloading scipy-1.9.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.4 MB)
    [2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m43.4/43.4 MB[0m [31m13.5 MB/s[0m eta [36m0:00:00[0m
    [?25h  Downloading scipy-1.8.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (41.6 MB)
    [2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m41.6/41.6 MB[0m [31m14.1 MB/s[0m eta [36m0:00:00[0m
    [?25h  Downloading scipy-1.8.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (41.6 MB)
    [2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m41.6/41.6 MB[0m [31m16.5 MB/s[0m eta [36m0:00:00[0m
    [?25h  Downloading scipy-1.7.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (39.3 MB)
    [2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m39.3/39.3 MB[0m [31m16.9 MB/s[0m eta [36m0:00:00[0m
    [?25h  Downloading scipy-1.7.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (28.4 MB)
    [2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m28.4/28.4 MB[0m [31m54.4 MB/s[0m eta [36m0:00:00[0m
    [?25h  Downloading scipy-1.7.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (28.4 MB)
    [2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m28.4/28.4 MB[0m [31m52.9 MB/s[0m eta [36m0:00:00[0m
    [?25h  Downloading scipy-1.6.3-cp38-cp38-manylinux1_x86_64.whl (27.2 MB)
    [2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m27.2/27.2 MB[0m [31m19.7 MB/s[0m eta [36m0:00:00[0m
    [?25h  Downloading scipy-1.6.2-cp38-cp38-manylinux1_x86_64.whl (27.2 MB)
    [2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m27.2/27.2 MB[0m [31m55.9 MB/s[0m eta [36m0:00:00[0m
    [?25h  Downloading scipy-1.6.1-cp38-cp38-manylinux1_x86_64.whl (27.3 MB)
    [2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m27.3/27.3 MB[0m [31m17.7 MB/s[0m eta [36m0:00:00[0m
    [?25h  Downloading scipy-1.6.0-cp38-cp38-manylinux1_x86_64.whl (27.2 MB)
    [2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m27.2/27.2 MB[0m [31m58.5 MB/s[0m eta [36m0:00:00[0m
    [?25h  Downloading scipy-1.5.4-cp38-cp38-manylinux1_x86_64.whl (25.8 MB)
    [2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m25.8/25.8 MB[0m [31m60.0 MB/s[0m eta [36m0:00:00[0m
    [?25hBuilding wheels for collected packages: datawig, numpy
      Building wheel for datawig (setup.py) ... [?25l[?25hdone
      Created wheel for datawig: filename=datawig-0.2.0-py3-none-any.whl size=72677 sha256=199c7628baba5ec7460a98551b7bd066d82196a7aaacd23785791e2ac56281af
      Stored in directory: /root/.cache/pip/wheels/75/98/7e/0361b6b68a18ee5bb5398f7ab50d54772f8bcf6946a1eb9ef2
      Building wheel for numpy (setup.py) ... [?25l[?25hdone
      Created wheel for numpy: filename=numpy-1.14.6-cp38-cp38-linux_x86_64.whl size=9740363 sha256=56810867285a831feb73d58dfada691ab3d48b894c58bb3857b18050a2b8e317
      Stored in directory: /root/.cache/pip/wheels/77/81/aa/e309a6725c1cb6f5b37c3c67b74828fd4db0827592ff4a4f85
    Successfully built datawig numpy
    Installing collected packages: typing, numpy, graphviz, scipy, pandas, mxnet, scikit-learn, datawig
      Attempting uninstall: numpy
        Found existing installation: numpy 1.21.6
        Uninstalling numpy-1.21.6:
          Successfully uninstalled numpy-1.21.6
      Attempting uninstall: graphviz
        Found existing installation: graphviz 0.10.1
        Uninstalling graphviz-0.10.1:
          Successfully uninstalled graphviz-0.10.1
      Attempting uninstall: scipy
        Found existing installation: scipy 1.7.3
        Uninstalling scipy-1.7.3:
          Successfully uninstalled scipy-1.7.3
      Attempting uninstall: pandas
        Found existing installation: pandas 1.3.5
        Uninstalling pandas-1.3.5:
          Successfully uninstalled pandas-1.3.5
      Attempting uninstall: scikit-learn
        Found existing installation: scikit-learn 1.0.2
        Uninstalling scikit-learn-1.0.2:
          Successfully uninstalled scikit-learn-1.0.2
    [31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.
    yellowbrick 1.5 requires numpy>=1.16.0, but you have numpy 1.14.6 which is incompatible.
    yellowbrick 1.5 requires scikit-learn>=1.0.0, but you have scikit-learn 0.22.1 which is incompatible.
    xarray 2022.12.0 requires numpy>=1.20, but you have numpy 1.14.6 which is incompatible.
    xarray 2022.12.0 requires pandas>=1.3, but you have pandas 0.25.3 which is incompatible.
    xarray-einstats 0.4.0 requires numpy>=1.20, but you have numpy 1.14.6 which is incompatible.
    xarray-einstats 0.4.0 requires scipy>=1.6, but you have scipy 1.5.4 which is incompatible.
    tifffile 2022.10.10 requires numpy>=1.19.2, but you have numpy 1.14.6 which is incompatible.
    thinc 8.1.6 requires numpy>=1.15.0, but you have numpy 1.14.6 which is incompatible.
    tensorflow 2.9.2 requires numpy>=1.20, but you have numpy 1.14.6 which is incompatible.
    tables 3.7.0 requires numpy>=1.19.0, but you have numpy 1.14.6 which is incompatible.
    statsmodels 0.12.2 requires numpy>=1.15, but you have numpy 1.14.6 which is incompatible.
    spacy 3.4.4 requires numpy>=1.15.0, but you have numpy 1.14.6 which is incompatible.
    seaborn 0.11.2 requires numpy>=1.15, but you have numpy 1.14.6 which is incompatible.
    scikit-image 0.18.3 requires numpy>=1.16.5, but you have numpy 1.14.6 which is incompatible.
    resampy 0.4.2 requires numpy>=1.17, but you have numpy 1.14.6 which is incompatible.
    pywavelets 1.4.1 requires numpy>=1.17.3, but you have numpy 1.14.6 which is incompatible.
    pymc 4.1.4 requires numpy>=1.15.0, but you have numpy 1.14.6 which is incompatible.
    pyerfa 2.0.0.1 requires numpy>=1.17, but you have numpy 1.14.6 which is incompatible.
    pyarrow 9.0.0 requires numpy>=1.16.6, but you have numpy 1.14.6 which is incompatible.
    prophet 1.1.1 requires numpy>=1.15.4, but you have numpy 1.14.6 which is incompatible.
    prophet 1.1.1 requires pandas>=1.0.4, but you have pandas 0.25.3 which is incompatible.
    plotnine 0.8.0 requires numpy>=1.19.0, but you have numpy 1.14.6 which is incompatible.
    plotnine 0.8.0 requires pandas>=1.1.0, but you have pandas 0.25.3 which is incompatible.
    pandas-gbq 0.17.9 requires numpy>=1.16.6, but you have numpy 1.14.6 which is incompatible.
    opencv-python 4.6.0.66 requires numpy>=1.17.3; python_version >= "3.8", but you have numpy 1.14.6 which is incompatible.
    opencv-python-headless 4.7.0.68 requires numpy>=1.17.0; python_version >= "3.7", but you have numpy 1.14.6 which is incompatible.
    opencv-python-headless 4.7.0.68 requires numpy>=1.17.3; python_version >= "3.8", but you have numpy 1.14.6 which is incompatible.
    opencv-contrib-python 4.6.0.66 requires numpy>=1.17.3; python_version >= "3.8", but you have numpy 1.14.6 which is incompatible.
    numba 0.56.4 requires numpy<1.24,>=1.18, but you have numpy 1.14.6 which is incompatible.
    mizani 0.7.3 requires pandas>=1.1.0, but you have pandas 0.25.3 which is incompatible.
    librosa 0.8.1 requires numpy>=1.15.0, but you have numpy 1.14.6 which is incompatible.
    kapre 0.3.7 requires numpy>=1.18.5, but you have numpy 1.14.6 which is incompatible.
    jaxlib 0.3.25+cuda11.cudnn805 requires numpy>=1.20, but you have numpy 1.14.6 which is incompatible.
    jax 0.3.25 requires numpy>=1.20, but you have numpy 1.14.6 which is incompatible.
    imgaug 0.4.0 requires numpy>=1.15, but you have numpy 1.14.6 which is incompatible.
    imbalanced-learn 0.8.1 requires scikit-learn>=0.24, but you have scikit-learn 0.22.1 which is incompatible.
    httpstan 4.6.1 requires numpy<2.0,>=1.16, but you have numpy 1.14.6 which is incompatible.
    h5py 3.1.0 requires numpy>=1.17.5; python_version == "3.8", but you have numpy 1.14.6 which is incompatible.
    gym 0.25.2 requires numpy>=1.18.0, but you have numpy 1.14.6 which is incompatible.
    google-colab 1.0.0 requires pandas>=1.1.0, but you have pandas 0.25.3 which is incompatible.
    db-dtypes 1.0.5 requires numpy<2.0dev,>=1.16.6, but you have numpy 1.14.6 which is incompatible.
    cvxpy 1.2.3 requires numpy>=1.15, but you have numpy 1.14.6 which is incompatible.
    cmdstanpy 1.0.8 requires numpy>=1.21, but you have numpy 1.14.6 which is incompatible.
    blis 0.7.9 requires numpy>=1.15.0, but you have numpy 1.14.6 which is incompatible.
    astropy 4.3.1 requires numpy>=1.17, but you have numpy 1.14.6 which is incompatible.
    aesara 2.7.9 requires numpy>=1.17.0, but you have numpy 1.14.6 which is incompatible.
    aeppl 0.0.33 requires numpy>=1.18.1, but you have numpy 1.14.6 which is incompatible.[0m[31m
    [0mSuccessfully installed datawig-0.2.0 graphviz-0.8.4 mxnet-1.4.0 numpy-1.14.6 pandas-0.25.3 scikit-learn-0.22.1 scipy-1.5.4 typing-3.6.6



```python
train.info()
```

    <class 'pandas.core.frame.DataFrame'>
    RangeIndex: 14760 entries, 0 to 14759
    Data columns (total 11 columns):
     #   Column             Non-Null Count  Dtype  
    ---  ------             --------------  -----  
     0   gender             14760 non-null  int64  
     1   age                14760 non-null  int64  
     2   hypertension       14760 non-null  int64  
     3   heart_disease      14760 non-null  int64  
     4   ever_married       14760 non-null  int64  
     5   work_type          14760 non-null  int64  
     6   Residence_type     14760 non-null  int64  
     7   avg_glucose_level  14760 non-null  float64
     8   bmi                14760 non-null  float64
     9   stroke             14760 non-null  int64  
     10  smoking_status     14760 non-null  object 
    dtypes: float64(2), int64(8), object(1)
    memory usage: 1.2+ MB



```python
import datawig

input_columns = list(set(train.columns) - set(['smoking_status']))
imputer = datawig.SimpleImputer(input_columns=input_columns,
                                output_column='smoking_status')
imputer.fit(train_df=train, num_epochs=50)
null_train = train[train['smoking_status'] == 'NaN']
null_imputed = imputer.predict(null_train)
imputed_train = pd.DataFrame(null_imputed)

imputed_train[imputed_train['smoking_status_imputed_proba'] > 0.6]
```

    INFO:root:
    ========== start: fit model
    2023-01-27 01:47:41,160 [INFO]  
    ========== start: fit model
    WARNING:root:Already bound, ignoring bind()
    2023-01-27 01:47:41,168 [WARNING]  Already bound, ignoring bind()
    INFO:root:Epoch[0] Batch [0-416]	Speed: 10382.63 samples/sec	cross-entropy=1.127312	smoking_status-accuracy=0.497752
    2023-01-27 01:47:41,826 [INFO]  Epoch[0] Batch [0-416]	Speed: 10382.63 samples/sec	cross-entropy=1.127312	smoking_status-accuracy=0.497752
    INFO:root:Epoch[0] Train-cross-entropy=1.111149
    2023-01-27 01:47:42,481 [INFO]  Epoch[0] Train-cross-entropy=1.111149
    INFO:root:Epoch[0] Train-smoking_status-accuracy=0.497368
    2023-01-27 01:47:42,489 [INFO]  Epoch[0] Train-smoking_status-accuracy=0.497368
    INFO:root:Epoch[0] Time cost=1.316
    2023-01-27 01:47:42,493 [INFO]  Epoch[0] Time cost=1.316
    INFO:root:Saved checkpoint to "smoking_status/model-0000.params"
    2023-01-27 01:47:42,501 [INFO]  Saved checkpoint to "smoking_status/model-0000.params"
    INFO:root:Epoch[0] Validation-cross-entropy=1.100210
    2023-01-27 01:47:42,587 [INFO]  Epoch[0] Validation-cross-entropy=1.100210
    INFO:root:Epoch[0] Validation-smoking_status-accuracy=0.503360
    2023-01-27 01:47:42,593 [INFO]  Epoch[0] Validation-smoking_status-accuracy=0.503360
    INFO:root:Epoch[1] Batch [0-416]	Speed: 10435.98 samples/sec	cross-entropy=1.092536	smoking_status-accuracy=0.511841
    2023-01-27 01:47:43,239 [INFO]  Epoch[1] Batch [0-416]	Speed: 10435.98 samples/sec	cross-entropy=1.092536	smoking_status-accuracy=0.511841
    INFO:root:Epoch[1] Train-cross-entropy=1.086385
    2023-01-27 01:47:43,862 [INFO]  Epoch[1] Train-cross-entropy=1.086385
    INFO:root:Epoch[1] Train-smoking_status-accuracy=0.506769
    2023-01-27 01:47:43,867 [INFO]  Epoch[1] Train-smoking_status-accuracy=0.506769
    INFO:root:Epoch[1] Time cost=1.282
    2023-01-27 01:47:43,879 [INFO]  Epoch[1] Time cost=1.282
    INFO:root:Saved checkpoint to "smoking_status/model-0001.params"
    2023-01-27 01:47:43,889 [INFO]  Saved checkpoint to "smoking_status/model-0001.params"
    INFO:root:Epoch[1] Validation-cross-entropy=1.091319
    2023-01-27 01:47:43,972 [INFO]  Epoch[1] Validation-cross-entropy=1.091319
    INFO:root:Epoch[1] Validation-smoking_status-accuracy=0.506720
    2023-01-27 01:47:43,982 [INFO]  Epoch[1] Validation-smoking_status-accuracy=0.506720
    INFO:root:Epoch[2] Batch [0-416]	Speed: 10403.59 samples/sec	cross-entropy=1.084327	smoking_status-accuracy=0.513639
    2023-01-27 01:47:44,629 [INFO]  Epoch[2] Batch [0-416]	Speed: 10403.59 samples/sec	cross-entropy=1.084327	smoking_status-accuracy=0.513639
    INFO:root:Epoch[2] Train-cross-entropy=1.078893
    2023-01-27 01:47:45,237 [INFO]  Epoch[2] Train-cross-entropy=1.078893
    INFO:root:Epoch[2] Train-smoking_status-accuracy=0.508649
    2023-01-27 01:47:45,240 [INFO]  Epoch[2] Train-smoking_status-accuracy=0.508649
    INFO:root:Epoch[2] Time cost=1.266
    2023-01-27 01:47:45,252 [INFO]  Epoch[2] Time cost=1.266
    INFO:root:Saved checkpoint to "smoking_status/model-0002.params"
    2023-01-27 01:47:45,260 [INFO]  Saved checkpoint to "smoking_status/model-0002.params"
    INFO:root:Epoch[2] Validation-cross-entropy=1.088610
    2023-01-27 01:47:45,346 [INFO]  Epoch[2] Validation-cross-entropy=1.088610
    INFO:root:Epoch[2] Validation-smoking_status-accuracy=0.509409
    2023-01-27 01:47:45,355 [INFO]  Epoch[2] Validation-smoking_status-accuracy=0.509409
    INFO:root:Epoch[3] Batch [0-416]	Speed: 12031.45 samples/sec	cross-entropy=1.079730	smoking_status-accuracy=0.514239
    2023-01-27 01:47:45,917 [INFO]  Epoch[3] Batch [0-416]	Speed: 12031.45 samples/sec	cross-entropy=1.079730	smoking_status-accuracy=0.514239
    INFO:root:Epoch[3] Train-cross-entropy=1.074676
    2023-01-27 01:47:46,471 [INFO]  Epoch[3] Train-cross-entropy=1.074676
    INFO:root:Epoch[3] Train-smoking_status-accuracy=0.510078
    2023-01-27 01:47:46,477 [INFO]  Epoch[3] Train-smoking_status-accuracy=0.510078
    INFO:root:Epoch[3] Time cost=1.121
    2023-01-27 01:47:46,482 [INFO]  Epoch[3] Time cost=1.121
    INFO:root:Saved checkpoint to "smoking_status/model-0003.params"
    2023-01-27 01:47:46,491 [INFO]  Saved checkpoint to "smoking_status/model-0003.params"
    INFO:root:Epoch[3] Validation-cross-entropy=1.087202
    2023-01-27 01:47:46,575 [INFO]  Epoch[3] Validation-cross-entropy=1.087202
    INFO:root:Epoch[3] Validation-smoking_status-accuracy=0.511425
    2023-01-27 01:47:46,582 [INFO]  Epoch[3] Validation-smoking_status-accuracy=0.511425
    INFO:root:Epoch[4] Batch [0-416]	Speed: 10612.16 samples/sec	cross-entropy=1.076733	smoking_status-accuracy=0.514688
    2023-01-27 01:47:47,218 [INFO]  Epoch[4] Batch [0-416]	Speed: 10612.16 samples/sec	cross-entropy=1.076733	smoking_status-accuracy=0.514688
    INFO:root:Epoch[4] Train-cross-entropy=1.071966
    2023-01-27 01:47:47,795 [INFO]  Epoch[4] Train-cross-entropy=1.071966
    INFO:root:Epoch[4] Train-smoking_status-accuracy=0.510605
    2023-01-27 01:47:47,804 [INFO]  Epoch[4] Train-smoking_status-accuracy=0.510605
    INFO:root:Epoch[4] Time cost=1.221
    2023-01-27 01:47:47,808 [INFO]  Epoch[4] Time cost=1.221
    INFO:root:Saved checkpoint to "smoking_status/model-0004.params"
    2023-01-27 01:47:47,815 [INFO]  Saved checkpoint to "smoking_status/model-0004.params"
    INFO:root:Epoch[4] Validation-cross-entropy=1.086610
    2023-01-27 01:47:47,887 [INFO]  Epoch[4] Validation-cross-entropy=1.086610
    INFO:root:Epoch[4] Validation-smoking_status-accuracy=0.512769
    2023-01-27 01:47:47,894 [INFO]  Epoch[4] Validation-smoking_status-accuracy=0.512769
    INFO:root:Epoch[5] Batch [0-416]	Speed: 12056.72 samples/sec	cross-entropy=1.074473	smoking_status-accuracy=0.514388
    2023-01-27 01:47:48,454 [INFO]  Epoch[5] Batch [0-416]	Speed: 12056.72 samples/sec	cross-entropy=1.074473	smoking_status-accuracy=0.514388
    INFO:root:Epoch[5] Train-cross-entropy=1.069813
    2023-01-27 01:47:49,068 [INFO]  Epoch[5] Train-cross-entropy=1.069813
    INFO:root:Epoch[5] Train-smoking_status-accuracy=0.510830
    2023-01-27 01:47:49,078 [INFO]  Epoch[5] Train-smoking_status-accuracy=0.510830
    INFO:root:Epoch[5] Time cost=1.185
    2023-01-27 01:47:49,084 [INFO]  Epoch[5] Time cost=1.185
    INFO:root:Saved checkpoint to "smoking_status/model-0005.params"
    2023-01-27 01:47:49,092 [INFO]  Saved checkpoint to "smoking_status/model-0005.params"
    INFO:root:Epoch[5] Validation-cross-entropy=1.085934
    2023-01-27 01:47:49,176 [INFO]  Epoch[5] Validation-cross-entropy=1.085934
    INFO:root:Epoch[5] Validation-smoking_status-accuracy=0.512097
    2023-01-27 01:47:49,184 [INFO]  Epoch[5] Validation-smoking_status-accuracy=0.512097
    INFO:root:Epoch[6] Batch [0-416]	Speed: 10279.15 samples/sec	cross-entropy=1.072534	smoking_status-accuracy=0.515737
    2023-01-27 01:47:49,841 [INFO]  Epoch[6] Batch [0-416]	Speed: 10279.15 samples/sec	cross-entropy=1.072534	smoking_status-accuracy=0.515737
    INFO:root:Epoch[6] Train-cross-entropy=1.068218
    2023-01-27 01:47:50,461 [INFO]  Epoch[6] Train-cross-entropy=1.068218
    INFO:root:Epoch[6] Train-smoking_status-accuracy=0.511056
    2023-01-27 01:47:50,472 [INFO]  Epoch[6] Train-smoking_status-accuracy=0.511056
    INFO:root:Epoch[6] Time cost=1.287
    2023-01-27 01:47:50,477 [INFO]  Epoch[6] Time cost=1.287
    INFO:root:Saved checkpoint to "smoking_status/model-0006.params"
    2023-01-27 01:47:50,483 [INFO]  Saved checkpoint to "smoking_status/model-0006.params"
    INFO:root:Epoch[6] Validation-cross-entropy=1.084715
    2023-01-27 01:47:50,559 [INFO]  Epoch[6] Validation-cross-entropy=1.084715
    INFO:root:Epoch[6] Validation-smoking_status-accuracy=0.510081
    2023-01-27 01:47:50,565 [INFO]  Epoch[6] Validation-smoking_status-accuracy=0.510081
    INFO:root:Epoch[7] Batch [0-416]	Speed: 12181.83 samples/sec	cross-entropy=1.071349	smoking_status-accuracy=0.515138
    2023-01-27 01:47:51,120 [INFO]  Epoch[7] Batch [0-416]	Speed: 12181.83 samples/sec	cross-entropy=1.071349	smoking_status-accuracy=0.515138
    INFO:root:Epoch[7] Train-cross-entropy=1.067165
    2023-01-27 01:47:51,656 [INFO]  Epoch[7] Train-cross-entropy=1.067165
    INFO:root:Epoch[7] Train-smoking_status-accuracy=0.510906
    2023-01-27 01:47:51,662 [INFO]  Epoch[7] Train-smoking_status-accuracy=0.510906
    INFO:root:Epoch[7] Time cost=1.097
    2023-01-27 01:47:51,668 [INFO]  Epoch[7] Time cost=1.097
    INFO:root:Saved checkpoint to "smoking_status/model-0007.params"
    2023-01-27 01:47:51,677 [INFO]  Saved checkpoint to "smoking_status/model-0007.params"
    INFO:root:Epoch[7] Validation-cross-entropy=1.086240
    2023-01-27 01:47:51,745 [INFO]  Epoch[7] Validation-cross-entropy=1.086240
    INFO:root:Epoch[7] Validation-smoking_status-accuracy=0.512769
    2023-01-27 01:47:51,751 [INFO]  Epoch[7] Validation-smoking_status-accuracy=0.512769
    INFO:root:Epoch[8] Batch [0-416]	Speed: 11465.68 samples/sec	cross-entropy=1.070121	smoking_status-accuracy=0.515588
    2023-01-27 01:47:52,341 [INFO]  Epoch[8] Batch [0-416]	Speed: 11465.68 samples/sec	cross-entropy=1.070121	smoking_status-accuracy=0.515588
    INFO:root:Epoch[8] Train-cross-entropy=1.066129
    2023-01-27 01:47:52,899 [INFO]  Epoch[8] Train-cross-entropy=1.066129
    INFO:root:Epoch[8] Train-smoking_status-accuracy=0.511958
    2023-01-27 01:47:52,908 [INFO]  Epoch[8] Train-smoking_status-accuracy=0.511958
    INFO:root:Epoch[8] Time cost=1.156
    2023-01-27 01:47:52,912 [INFO]  Epoch[8] Time cost=1.156
    INFO:root:Saved checkpoint to "smoking_status/model-0008.params"
    2023-01-27 01:47:52,922 [INFO]  Saved checkpoint to "smoking_status/model-0008.params"
    INFO:root:Epoch[8] Validation-cross-entropy=1.087106
    2023-01-27 01:47:52,989 [INFO]  Epoch[8] Validation-cross-entropy=1.087106
    INFO:root:Epoch[8] Validation-smoking_status-accuracy=0.510081
    2023-01-27 01:47:52,993 [INFO]  Epoch[8] Validation-smoking_status-accuracy=0.510081
    INFO:root:Epoch[9] Batch [0-416]	Speed: 12016.20 samples/sec	cross-entropy=1.069351	smoking_status-accuracy=0.517686
    2023-01-27 01:47:53,554 [INFO]  Epoch[9] Batch [0-416]	Speed: 12016.20 samples/sec	cross-entropy=1.069351	smoking_status-accuracy=0.517686
    INFO:root:Epoch[9] Train-cross-entropy=1.065555
    2023-01-27 01:47:54,183 [INFO]  Epoch[9] Train-cross-entropy=1.065555
    INFO:root:Epoch[9] Train-smoking_status-accuracy=0.512786
    2023-01-27 01:47:54,191 [INFO]  Epoch[9] Train-smoking_status-accuracy=0.512786
    INFO:root:Epoch[9] Time cost=1.199
    2023-01-27 01:47:54,196 [INFO]  Epoch[9] Time cost=1.199
    INFO:root:Saved checkpoint to "smoking_status/model-0009.params"
    2023-01-27 01:47:54,203 [INFO]  Saved checkpoint to "smoking_status/model-0009.params"
    INFO:root:Epoch[9] Validation-cross-entropy=1.088431
    2023-01-27 01:47:54,285 [INFO]  Epoch[9] Validation-cross-entropy=1.088431
    INFO:root:Epoch[9] Validation-smoking_status-accuracy=0.506720
    2023-01-27 01:47:54,290 [INFO]  Epoch[9] Validation-smoking_status-accuracy=0.506720
    INFO:root:Epoch[10] Batch [0-416]	Speed: 12048.85 samples/sec	cross-entropy=1.069075	smoking_status-accuracy=0.515588
    2023-01-27 01:47:54,851 [INFO]  Epoch[10] Batch [0-416]	Speed: 12048.85 samples/sec	cross-entropy=1.069075	smoking_status-accuracy=0.515588
    INFO:root:Epoch[10] Train-cross-entropy=1.065073
    2023-01-27 01:47:55,387 [INFO]  Epoch[10] Train-cross-entropy=1.065073
    INFO:root:Epoch[10] Train-smoking_status-accuracy=0.511958
    2023-01-27 01:47:55,395 [INFO]  Epoch[10] Train-smoking_status-accuracy=0.511958
    INFO:root:Epoch[10] Time cost=1.106
    2023-01-27 01:47:55,400 [INFO]  Epoch[10] Time cost=1.106
    INFO:root:Saved checkpoint to "smoking_status/model-0010.params"
    2023-01-27 01:47:55,407 [INFO]  Saved checkpoint to "smoking_status/model-0010.params"
    INFO:root:No improvement detected for 5 epochs compared to 1.08593411086708 last error obtained: 1.089427766620472, stopping here
    2023-01-27 01:47:55,477 [INFO]  No improvement detected for 5 epochs compared to 1.08593411086708 last error obtained: 1.089427766620472, stopping here
    INFO:root:
    ========== done (14.322499990463257 s) fit model
    2023-01-27 01:47:55,481 [INFO]  
    ========== done (14.322499990463257 s) fit model



    ---------------------------------------------------------------------------

    ValueError                                Traceback (most recent call last)

    <ipython-input-50-cdbfc49ad619> in <module>
          6 imputer.fit(train_df=train, num_epochs=50)
          7 null_train = train[train['smoking_status'] == 'NaN']
    ----> 8 null_imputed = imputer.predict(null_train)
          9 imputed_train = pd.DataFrame(null_imputed)
         10 


    /usr/local/lib/python3.8/dist-packages/datawig/simple_imputer.py in predict(self, data_frame, precision_threshold, imputation_suffix, score_suffix, inplace)
        417         :return: data_frame original dataframe with imputations and likelihood in additional column
        418         """
    --> 419         imputations = self.imputer.predict(data_frame, precision_threshold, imputation_suffix,
        420                                            score_suffix, inplace=inplace)
        421 


    /usr/local/lib/python3.8/dist-packages/datawig/imputer.py in predict(self, data_frame, precision_threshold, imputation_suffix, score_suffix, inplace)
        827                 *[c.input_columns for c in self.label_encoders if isinstance(c, NumericalEncoder)]))
        828 
    --> 829         predictions = self.predict_above_precision(data_frame, precision_threshold).items()
        830         for label, imputations in predictions:
        831             imputation_col = label + imputation_suffix


    /usr/local/lib/python3.8/dist-packages/datawig/imputer.py in predict_above_precision(self, data_frame, precision_threshold)
        878 
        879         """
    --> 880         mxnet_iter = self.__mxnet_iter_from_df(data_frame)
        881         return self.__predict_above_precision_mxnet_iter(mxnet_iter,
        882                                                          precision_threshold=precision_threshold)


    /usr/local/lib/python3.8/dist-packages/datawig/imputer.py in __mxnet_iter_from_df(self, data_frame)
       1042         :return: ImputerIterDf
       1043         """
    -> 1044         return ImputerIterDf(
       1045             data_frame=data_frame,
       1046             data_columns=self.data_encoders,


    /usr/local/lib/python3.8/dist-packages/datawig/iterators.py in __init__(self, data_frame, data_columns, label_columns, batch_size)
        229         # custom padding for having to discard the last batch in mxnet for sparse data
        230         padding_n_rows = self._n_rows_padding(data_frame)
    --> 231         self.start_padding_idx = int(data_frame.index.max() + 1)
        232         for idx in range(self.start_padding_idx, self.start_padding_idx + padding_n_rows):
        233             data_frame.loc[idx, :] = data_frame.loc[self.start_padding_idx - 1, :]


    ValueError: cannot convert float NaN to integer



```python
print("정확도가 이전의 랜덤포레스트와 거의 유사하거나 낮은 경우(60% 미만)의 비율 : {:.2f}%".format(imputed_train[imputed_train['smoking_status_imputed_proba'] <= 0.6].shape[0] / train.shape[0] * 100))
```

# Unknown 데이터 Known 데이터의 smoking_status 비율로 랜덤하게 분할

Known 데이터의 smoking_status 특성을 분석하여 Unknown 데이터를 분류하려 하였으나

정확도를 높이는 방법을 끝내 찾지 못하였고 그 부분에 대해서는 결측값 처리를 어떻게 해야할지 공부의 필요성을 느끼게 됨.

정확도가 8-90% 정도의 어느정도 납득할만한 정확도가 나오지 않아서

Unknown 데이터를 Known 데이터의 smoking_status 비율로 랜덤하게 분할하기로 결론지음.


```python
train.columns
```


```python
train['id'] = train_id
train = train[['id','gender', 'age', 'hypertension', 'heart_disease', 'ever_married',
       'work_type', 'Residence_type', 'smoking_status', 'avg_glucose_level', 'bmi',  'stroke']]
train
```


```python
known = train[train['smoking_status'] != 'Unknown']
known.reset_index(drop = True, inplace = True)

unknown = train[train['smoking_status'] == 'Unknown']
unknown.reset_index(drop = True, inplace = True)
```


```python
print(known[known['smoking_status'] == 'never smoked'].shape[0] / known.shape[0] * 100,
    known[known['smoking_status'] == 'formerly smoked'].shape[0] / known.shape[0] * 100,
    known[known['smoking_status'] == 'smokes'].shape[0] / known.shape[0] * 100)
```


```python
import random

unknown_indexes = list(unknown.index)

not_fullcat = 3

never_smoked_filter = int(unknown.shape[0] * 0.01 * round(known[known['smoking_status'] == 'never smoked'].shape[0] / known.shape[0] * 100))
formerly_smoked_filter = int(unknown.shape[0] * 0.01 * round(known[known['smoking_status'] == 'formerly smoked'].shape[0] / known.shape[0] * 100))

for n in range(len(unknown_indexes)):
    random_choice = random.choice(unknown_indexes)
    if unknown.loc[random_choice, "smoking_status"] != "Unknown":
        continue
    else:
        if not_fullcat == 3:
            unknown.loc[random_choice, "smoking_status"] = 'never smoked'
            unknown_indexes.remove(random_choice)
            if unknown[unknown['smoking_status'] == 'never smoked'].shape[0] == never_smoked_filter:
                not_fullcat -= 1
        elif not_fullcat == 2:
            unknown.loc[random_choice, "smoking_status"] = 'formerly smoked'
            unknown_indexes.remove(random_choice)
            if unknown[unknown['smoking_status'] == 'formerly smoked'].shape[0] == formerly_smoked_filter:
                not_fullcat -= 1
        else:
            unknown.loc[unknown_indexes, "smoking_status"] = 'smokes'
            break
```


```python
fig, ax = plt.subplots(1,2,figsize=(10,10), constrained_layout = True)

known['smoking_status'].value_counts().plot.pie(explode = [0, 0.08, 0.08], autopct='%.1f%%', ax = ax[0])
ax[0].set_title("known smoking_status pie plot")
ax[0].set_ylabel("")

unknown['smoking_status'].value_counts().plot.pie(explode = [0, 0.08, 0.08], autopct='%.1f%%', ax = ax[1])
ax[1].set_title("unknown smoking_status pie plot")
ax[1].set_ylabel("")
```


```python
train = pd.concat([known, unknown])
train = train.sort_values('id')
train.reset_index(drop = True, inplace = True)
train
```


```python
from sklearn.preprocessing import LabelEncoder

smoking_status_answer = train['smoking_status'].unique()
encoder = LabelEncoder()
encoder.fit(smoking_status_answer)
train['smoking_status'] = encoder.transform(train['smoking_status'])
print(smoking_status_answer, encoder.transform(smoking_status_answer))
```

* 정제된 전체 데이터를 갖고 EDA 분석해줘야함...

# Stroke EDA 분석

* 뇌졸중의 주요 원인 (출처 : https://www.stroke.or.kr/stroke/?doc=3#c1)
    1. 고혈압

    2. 당뇨병 : [정상치] 70~99 ㎎/ℓ 8시간 이상 공복 후 측정한 혈당이 126 mg/dL 이상인 경우 당뇨병으로 진단이 됩니다.
    
    (출처 : https://www.kslm.org/sub01/sub03.html)

    3. 심장병

    4. 고지혈증 (데이터에 관련 정보 없음)

    5. 흡연

    6. 음주 (데이터에 관련 정보 없음)

    7. 비만 :  WHO(Asia-Pacific Region) 와 대한비만학회에서 비만의 기준은 체질량지수 25kg/㎡ 이상으로 정의하였다.

    (출처 : https://dietitian.or.kr/work/business/kb_c_adult_obesity_verdict.do)




```python
from google.colab import drive
drive.mount('/content/drive')
```

    Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount("/content/drive", force_remount=True).



```python
!
```

    [NbConvertApp] Converting notebook /content/drive/MyDrive/Colab/프기초/14_struct_and_class.ipynb to markdown
    [NbConvertApp] Writing 2969 bytes to /content/drive/MyDrive/Colab/프기초/14_struct_and_class.md

